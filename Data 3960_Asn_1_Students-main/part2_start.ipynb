{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Azim_Utility\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.tree\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "\n",
    "##Seaborn for fancy plots. \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (4,4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3950 Assignment 1: Part 2\n",
    "\n",
    "For this assignment we want to use some sort of tree based model to classify the data below. We have a very small training set, so overfitting is a very real concern. \n",
    "\n",
    "Some specifics for this assignment:\n",
    "<ul>\n",
    "<li>Please use the show_eda to control if EDA stuff is shown. I don't really need to see all the EDA stuff (nor do you after you've done it), so we can make it configurable with a variable to speed up time. Please set this FALSE when you submit, so I can run all and see the outcome without histograms etc...\n",
    "<li>Please ensure that whatever model you end up with is in a variable named best at the end.\n",
    "<li>Please use some pipeline in prepping the data. The test data is in an identical format to the training data, so whatever pipeline you've created for your training will work for the testing. \n",
    "<li>The accuracy scoring will be an average of accuracy and roc_auc. \n",
    "</ul>\n",
    "\n",
    "### Grading Metrics\n",
    "<ul>\n",
    "<li><b>Pipeline Used - 10pts</b> The data loading needs to be in a pipeline. See the test part for illustration. When testing I'll call your pipe with the new data (format is identical to training), so any prep stuff should be in the pipeline. \n",
    "<li><b>Tree Based Model Used - 5pts</b> The model used for classification needs to be some variety of tree, beyond that it is up to you. \n",
    "<li><b>Accuracy - 5pts</b> The final accuracy acheived. This will be a rough ranking, I'm assuming most people will get a similar level of accuracy, marks will only be deducted if yours is far wosrse, as that's an indication that you probably didn't take any/many steps to improve things. \n",
    "<li><b>Clarity and Formatting - 5pts</b> Is it organized and can I read it?\n",
    "    <ul>\n",
    "    <li> <b>Note:</b> for this assignment, and in general, please get rid of my comments and replace them with your own. I'm going to read this, so all of these instructions aren't really required. Think of this as a template, get rid of the stuff that isn't needed, and leave only the things you need to explain your code. \n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "For submission, please drop the URL for your repository in the dropbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please change to your name.\n",
    "name = \"Azim's\"\n",
    "\n",
    "#Please use this to control EDA. \n",
    "show_eda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "      <th>var_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  var_1  var_2  var_3  var_4  var_5  var_6  var_7  var_8  var_9  \\\n",
       "246       1  0.323  0.373  0.862  0.413  0.891  0.500  0.231  0.307  0.461   \n",
       "147       0  0.858  0.813  0.899  0.729  0.164  0.519  0.166  0.030  0.210   \n",
       "107       0  0.915  0.671  0.243  0.943  0.786  0.867  0.475  0.034  0.397   \n",
       "109       1  0.204  0.559  0.314  0.523  0.662  0.385  0.486  0.311  0.636   \n",
       "33        0  0.825  0.449  0.389  0.067  0.728  0.096  0.628  0.060  0.870   \n",
       "\n",
       "     ...  var_191  var_192  var_193  var_194  var_195  var_196  var_197  \\\n",
       "246  ...    0.656    0.846    0.904    0.281    0.182    0.326    0.541   \n",
       "147  ...    0.007    0.117    0.617    0.066    0.558    0.498    0.621   \n",
       "107  ...    0.808    0.273    0.471    0.531    0.083    0.169    0.869   \n",
       "109  ...    0.693    0.896    0.768    0.143    0.731    0.769    0.437   \n",
       "33   ...    0.802    0.931    0.580    0.960    0.524    0.658    0.967   \n",
       "\n",
       "     var_198  var_199  var_200  \n",
       "246    0.393    0.033    0.458  \n",
       "147    0.864    0.986    0.003  \n",
       "107    0.335    0.929    0.106  \n",
       "109    0.526    0.669    0.946  \n",
       "33     0.344    0.990    0.656  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "df = pd.read_csv(\"training.csv\")\n",
    "df = df.drop(columns={\"id\"})\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting\n",
    "\n",
    "For this assignment, you have a small training set, so combatting overfitting is key in being accurate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 201)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 201)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=df.copy()\n",
    "# Creating my own test dataframe which will be my example of testing data the model has not seen.\n",
    "np.random.seed(0)\n",
    "test.drop(test.sample(frac=0.25).index, inplace=True) #randomly removes 25% of the rows\n",
    "test.to_csv('azimTEST.csv', index=False) #save new file as azimTEST.csv\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe consists of only Numerical Columns.\n",
      "Number of Numerical Columns: 201\n",
      "Total NULL Values in Dataframe:  0\n",
      "Number of Numerical values in dataframe that are < 0 (negative values) : 0\n"
     ]
    }
   ],
   "source": [
    "# Can not use our Azim_Utility.EDA() class because there are over 200 columns. So, .......\n",
    "\n",
    "# Create function to quickly check the details on the datarfame. Detailes include:\n",
    "# Number of Categorical Columns\n",
    "# Number ofNumerical Columns\n",
    "# Number of missing values\n",
    "# Number of values < 0 to decide on what scaling method to use.\n",
    "def chek_cols(data):\n",
    "    Categorical_Columns=df.select_dtypes(include=['object']).columns\n",
    "    Numerical_Columns=df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    if len(Categorical_Columns) > 0 and len(Numerical_Columns) == 0:\n",
    "        print('Dataframe consists of only Categorical Columns.')\n",
    "        print('Number of Catagorical Columns:',len(Categorical_Columns))\n",
    "        print('Total NULL Values in Dataframe: ',(df.isnull().sum()).sum()) # checking and prining sum of null values \n",
    "    elif len(Categorical_Columns) == 0 and len(Numerical_Columns) > 0:\n",
    "        print('Dataframe consists of only Numerical Columns.')\n",
    "        print('Number of Numerical Columns:', len(Numerical_Columns))\n",
    "        print('Total NULL Values in Dataframe: ',(df.isnull().sum()).sum()) # checking and prining sum of null values \n",
    "        print('Number of Numerical values in dataframe that are < 0 (negative values) :', ((df< 0).sum()).sum())\n",
    "    else:\n",
    "        print('Dataframe has a combination of Categorical and Numerical Columns.')\n",
    "        print('Number of Catagorical Columns:',len(Categorical_Columns))\n",
    "        print('Number of Numerical Columns:', len(Numerical_Columns))\n",
    "        print('Total NULL Values in Dataframe: ',(df.isnull().sum()).sum()) # checking and prining sum of null values \n",
    "        print('Number of Numerical values < 0 (negative values):', ((df< 0).sum()).sum())\n",
    "    return \n",
    "    \n",
    "chek_cols(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which Tree Classification to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (250, 200)\n",
      "Y Shape: (250, 1)\n",
      "At default settings, Decision Tree Mean Accuracy after 25 runs:  0.52\n",
      "At default settings, Random Forest Mean Accuracy after 25 runs:  0.6285714285714286\n",
      "\n",
      "Looking at the results above (@ default settings), we will use Randon Forest Classification.\n"
     ]
    }
   ],
   "source": [
    "# Function DTorRF to check to see which Tree is better at default classification tree settings.\n",
    "# for pipeline() we are using Standardscaler() because all columns are numeric and no values < 0.\n",
    "def DTorRF(data, target, runs):\n",
    "\n",
    "    X = np.array(df.drop(columns={target}))\n",
    "    y = np.array(df[target]).reshape(-1,1)\n",
    "\n",
    "    #X = (df.drop(columns={target})).values\n",
    "    print('X Shape:',X.shape)\n",
    "    #y = (df[target]).values\n",
    "    print('Y Shape:',y.shape)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y.ravel(), test_size=0.25, random_state=0)\n",
    "    # create the pipeline\n",
    "    pipeline = Pipeline([('scaler', StandardScaler())]) # using standardscaler()\n",
    "\n",
    "    # fit the pipeline to the train data\n",
    "    pipeline.fit(X_train)\n",
    "\n",
    "    # transform the train and test data\n",
    "    X_train_transformed = pipeline.transform(X_train)\n",
    "    X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "    # create lists to compile the accuracies for each tree\n",
    "    dt_accuracies = [] \n",
    "    rf_accuracies = []\n",
    "    t=runs\n",
    "    \n",
    "    # perform the test for r trails: r being the number of trails wanted.\n",
    "    for i in range(t):\n",
    "        # Decision Tree\n",
    "        dt = DecisionTreeClassifier()\n",
    "        dt.fit(X_train_transformed, y_train.ravel())\n",
    "        dt_pred = dt.predict(X_test_transformed)\n",
    "        dt_acc = accuracy_score(y_test, dt_pred)\n",
    "        dt_accuracies.append(dt_acc)\n",
    "\n",
    "        # Random Forest\n",
    "        rf = RandomForestClassifier()\n",
    "        rf.fit(X_train_transformed, y_train.ravel())\n",
    "        rf_pred = rf.predict(X_test_transformed)\n",
    "        rf_acc = accuracy_score(y_test, rf_pred)\n",
    "        rf_accuracies.append(rf_acc)\n",
    "\n",
    "    # print the mean accuracy for each model\n",
    "    # Calculating the mean of the all accuracies from trails.\n",
    "    print(f\"At default settings, Decision Tree Mean Accuracy after {t} runs: \", np.mean(dt_accuracies)) \n",
    "    print(f\"At default settings, Random Forest Mean Accuracy after {t} runs: \", np.mean(rf_accuracies))\n",
    "\n",
    "    # Deduce Clasisfication model based on highest mean score for each Tree used.\n",
    "    if (np.mean(dt_accuracies))> (np.mean(rf_accuracies)):\n",
    "        print()\n",
    "        print('Looking at the results above (@ default settings), we will use Decision Tree Classification')\n",
    "    else:\n",
    "        print()\n",
    "        print('Looking at the results above (@ default settings), we will use Randon Forest Classification.')\n",
    "    return\n",
    "    \n",
    "DTorRF(df, 'target', 25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do Modelling Stuff\n",
    "\n",
    "Make a tree model (of some vareity) and make it fit well. Keep in mind the possibility of your tree overfitting, and think of steps you may need to combat that shoudl it occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo the above, but with a pipeline\n",
    "# Since all the columns are numeric and have NO null values, hence we only need to use the StandardScaler() or RobustScaler().fit\n",
    "# Why Standardscaler?\n",
    "# StandardScaler() follows Standard Normal Distribution (SND). Therefore, it makes mean = 0 and scales the data to unit variance. \n",
    "# MinMaxScaler() scales all the data features in the range [0, 1] or else in the range [-1, 1] if there are negative values in the dataset.\n",
    "# RobustScaler() This Scaler removes the median and scales the data according to the quantile range (defaults to the IQR range)\n",
    "\n",
    "estimator=RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "scaler_RS=preprocessing.RobustScaler() \n",
    "scaler_SS=preprocessing.StandardScaler()\n",
    "scaler_MM=preprocessing.MinMaxScaler()\n",
    "\n",
    "#Create Pipeline Steps\n",
    "pipeline_steps=[('pre', scaler_SS), ('rf', estimator)]\n",
    "pipe=Pipeline(pipeline_steps)\n",
    "\n",
    "# Split dataframe\n",
    "X=np.array(df.drop(columns={'target'}))\n",
    "y=np.array(df['target']).reshape(-1,1) # using np.array().reshape(-1,1) because some sklearn classification models require a 2D array.\n",
    "\n",
    "#X = (df.drop(columns={'target'})).values\n",
    "#y = (df['target']).values\n",
    "\n",
    "\n",
    "#test, train split\n",
    "#using ravel() because of value error in previous code.\n",
    "# ravel() is used to create a contiguous flattened array.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.ravel(), test_size=0.3, random_state=0)\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "# n_estimators: The n_estimators parameter specifies the number of trees in the forest of the model. The default value for this parameter is 10, which means that 10 different decision trees will be constructed in the random forest.\n",
    "# max_depth: The max_depth parameter specifies the maximum depth of each Decision Tree. The default value for max_depth is None, which means that each tree will expand until every leaf is pure. A pure leaf is one where all of the data on the leaf comes from the same class.\n",
    "# min_samples_split: The min_samples_split parameter specifies the minimum number of samples required to split an internal leaf node. The default value for this parameter is 2, which means that an internal node must have at least two samples before it can be split to have a more specific classification.\n",
    "# min_samples_leaf: The min_samples_leaf parameter specifies the minimum number of samples required to be at a leaf node. The default value for this parameter is 1, which means that every leaf must have at least 1 sample that it classifies.\n",
    "\n",
    "rf_para = {'rf__min_samples_split':[2,3,4],\n",
    "            'rf__max_depth':[3,4,5],\n",
    "            'rf__n_estimators':[200, 210, 215, 220, 225],\n",
    "            # 'rf__criterion':[\"Gini\"],\n",
    "            'rf__max_samples':[.0025, .05, .0525, .06]} # the number of samples to draw from X to train each base estimator\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=rf_para, cv=5, n_jobs=-1) # cv:Cross-Validation set at 5\n",
    "grid.fit(X_train, y_train.ravel())\n",
    "best=grid.best_estimator_ #  estimator which gave highest score (or smallest loss if specified) on the left out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5866666666666667\n",
      "Pipeline(steps=[('pre', StandardScaler()),\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_samples=0.2,\n",
      "                                        min_samples_split=8, n_estimators=175,\n",
      "                                        n_jobs=-1))])\n"
     ]
    }
   ],
   "source": [
    "# Test 1(gini &/or Entropy): Took 26mins to run\n",
    "#print(best.score(X_test, y_test))\n",
    "#print(best)\n",
    "#'rf__min_samples_split':[4,5,6,7,8],\n",
    "            #'rf__max_depth':[3,4,5,6,7,8,9],\n",
    "            #'rf__n_estimators':[80, 100, 150, 175, 200, 225],\n",
    "            #'rf__criterion':[\"gini\",\"entropy\"], taking to long,\n",
    "            #'rf__max_samples':[0.2,.3, .4, .5, .6, .7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6266666666666667\n",
      "Pipeline(steps=[('pre', StandardScaler()),\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_samples=0.6,\n",
      "                                        min_samples_split=4, n_estimators=225,\n",
      "                                        n_jobs=-1))])\n"
     ]
    }
   ],
   "source": [
    "#test 2 (gini):\n",
    "#print(best.score(X_test, y_test))\n",
    "#print(best)\n",
    "\n",
    "#{'rf__min_samples_split':[4,5,6], \n",
    "#'rf__max_depth':[2,3,4], \n",
    "#'rf__n_estimators':[180, 200, 210], \n",
    "\n",
    "#'rf__max_samples':[.4, .5, .6]} # the number of samples to draw from X to train each base estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "Pipeline(steps=[('pre', StandardScaler()),\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_samples=0.05,\n",
      "                                        min_samples_split=5, n_estimators=215,\n",
      "                                        n_jobs=-1))])\n"
     ]
    }
   ],
   "source": [
    "#Test 3 (gini):\n",
    "#print(best.score(X_test, y_test))\n",
    "#print(best)\n",
    "\n",
    "#'rf__min_samples_split':[3,4,5], \n",
    "#'rf__max_depth':[2,3,4], \n",
    "#'rf__n_estimators':[180, 200, 210, 215], \n",
    "\n",
    "#'rf__max_samples':[.4, .5, .6]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5066666666666667\n",
      "Pipeline(steps=[('pre', StandardScaler()),\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(criterion='entropy', max_depth=3,\n",
      "                                        max_samples=0.05, min_samples_split=5,\n",
      "                                        n_estimators=210, n_jobs=-1))])\n"
     ]
    }
   ],
   "source": [
    "#Test 4 (entropy)\n",
    "#print(best.score(X_test, y_test))\n",
    "#print(best)\n",
    "\n",
    "#'rf__min_samples_split':[3,4,5],\n",
    "# 'rf__max_depth':[2,3,4],\n",
    "# 'rf__n_estimators':[180, 200, 210, 215, 220],\n",
    "# 'rf__criterion':[\"entropy\"],\n",
    "# 'rf__max_samples':[.01, .02, .03, .05]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5333333333333333\n",
      "Pipeline(steps=[('pre', StandardScaler()),\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_samples=0.06,\n",
      "                                        min_samples_split=4, n_estimators=215,\n",
      "                                        n_jobs=-1))])\n"
     ]
    }
   ],
   "source": [
    "#Test 5 (gini)\n",
    "#print(best.score(X_test, y_test))\n",
    "#print(best)\n",
    "\n",
    "#'rf__min_samples_split':[2,3,4],\n",
    "# 'rf__max_depth':[3,4,5],\n",
    "# 'rf__n_estimators':[200, 210, 215, 220, 225],\n",
    "# 'rf__criterion':[\"Gini\"],\n",
    "# 'rf__max_samples':[.0025, .05, .0525, .06]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finishing\n",
    "\n",
    "At the conclusion, please name your best model \"best\". If you look down below in the testing stuff, it should be usable to score as \"best\". \n",
    "\n",
    "You should be able to call it like this and it should work (with whatever data names you have)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5333333333333333\n",
      "Pipeline(steps=[('pre', StandardScaler()),\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(max_depth=3, max_samples=0.06,\n",
      "                                        min_samples_split=4, n_estimators=215,\n",
      "                                        n_jobs=-1))])\n"
     ]
    }
   ],
   "source": [
    "print(best.score(X_test, y_test)) #using Test 5 results\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Please leave the stuff below as-is in your file. \n",
    "\n",
    "This will take your best model and score it with the test data. If you want to test to make sure that yours works, make a copy of the data file and rename it testing.csv, then make sure this runs ok. I will do the same, but the contents of my test file will be different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.730393825899444\n",
      "0.7393617021276596\n",
      "Azim's 0.7348777640135518\n"
     ]
    }
   ],
   "source": [
    "#Load Test Data\n",
    "test_df = pd.read_csv(\"azimTEST.csv\")\n",
    "#test_df = test_df.drop(columns={\"id\"}) # Please uncheck this when using your test file.\n",
    "#Create tests and score\n",
    "test_y = np.array(test_df[\"target\"]).reshape(-1,1)\n",
    "test_X = np.array(test_df.drop(columns={\"target\"}))\n",
    "\n",
    "preds = best.predict(test_X)\n",
    "\n",
    "roc_score = roc_auc_score(test_y, preds)\n",
    "acc_score = accuracy_score(test_y, preds)\n",
    "\n",
    "print(roc_score)\n",
    "print(acc_score)\n",
    "print(name, np.mean([roc_score, acc_score]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Accuracy Changes Were Used\n",
    "\n",
    "Please list here what you did to try to increase accuracy and/or limit overfitting:\n",
    "\n",
    "<ul>\n",
    "<li>Increase Accuracy: Increase the Number of Decision Trees within a Forest (By increasing the n_estimators)\n",
    "<li>Limit Overfitting: Reducing Tree depth (By decreasing max_depth)\n",
    "<li>Limit Overfitting: Reducing the number of Variables samples at each split:\n",
    "<li>Limit Overfitting: Using more data: Unfortunately we dont have have more training data.\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bdbdacd0101e68079a1bddb8194690255e5689c62d1f789cd03eec87f1fa8a92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
